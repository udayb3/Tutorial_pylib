{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### `bs4` library has different classes for different page type:\n",
    "  - _BeautifulSoup_ for _HTML_ pages\n",
    "  - _BeautifulStoneSoup_ for _XML_ pages\n",
    "\n",
    "- #### With the help of the request module, it is used as a scraping library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import requests as rq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing\n",
    "  - #### _BeautifulSoup_ acts as a parser for the HTML and XML pages. __It can even use heristics to figure out the correct parsing for incorrectly parsed document__. With HTML soup does not know sometimes about the self-closing tags.\n",
    "\n",
    "  - #### Only unicode string are stored in the data structure created by soup.\n",
    "\n",
    "  - #### While creating the soup we can also relay that from which encoding are we taking the code.\n",
    "    > soup = BeautifulSoup( site, from_encoding=\"euc-jp\" )\n",
    "\n",
    "  - #### Other options such as turning off smart quotes can be turned off.\n",
    "\n",
    "  - #### A parser object (soup) is a nested, connected data structure corresponding to the structure of an XML/HTML document. The parser object contains two other types of objects: Tag objects, which correspond to tags like the `<TITLE>` tag and the `<B>` tags; and NavigableString objects which correspond to strings like `Page title` and `This is paragraph`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   TITLE OF THE PAGE\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <div class=\"container\" id=\"main\">\n",
      "   <div class=\"head\" id=\"head1\">\n",
      "    <h1>\n",
      "     #RANDOM_TITLE\n",
      "    </h1>\n",
      "   </div>\n",
      "   <div class=\"info\" id=\"head2\">\n",
      "    <p align=\"center\" class=\"para\" id=\"para1\">\n",
      "     Here is the typical which might be provided in the page about the site\n",
      "     <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/>\n",
      "    </p>\n",
      "    <p class=\"para\" id=\"para2\">\n",
      "     Here is some more info about the site.\n",
      "    </p>\n",
      "   </div>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc=[ '<html><head><title>TITLE OF THE PAGE</title></head>', \n",
    "      '<body> <div class=\"container\" id=\"main\"> <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div> <div class=\"info\" id=\"head2\"> <p class=\"para\" id=\"para1\" align=\"center\">Here is the typical which might be provided in the page about the site <link rel=\"icon\" href=\"#\" sizes=\"414X414\" /> </p>',\n",
    "      '<p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div> </div>',\n",
    "      '</html>'\n",
    "]\n",
    "\n",
    "# Parsing the html document\n",
    "self_soup = BeautifulSoup(''.join(doc) )\n",
    "print( self_soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generally, the __Navigating down__ can be done through 2 ways:\n",
    "  - `soup.#elm_name`  i.e. directly referencing the element's name.\n",
    "    -  We can directly use the tag name and add them like this `div.div.a`. This returns the first such tag present and `None` if no such tag is there.\n",
    "\n",
    "  - `soup.contents`/`soup.children`/`soup.descendants` i.e. referencing the elements children and descendants directly.\n",
    "    - `.contents` gives the whole content of that tag including any other tag which is in there.\n",
    "    - `.children` can be seen as a list of all the contents in the children.\n",
    "    - `.descendants` returns the list of all the descendants and their children in the format of a list.\n",
    "\n",
    "  - Apart from this, `.strings`/`.stripped_strings` can be used to get the inner string of the tag. \n",
    "    - `.strings` returns a list iterator which can be used with the for loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st div tag:\n",
      "\n",
      "<div class=\"container\" id=\"main\"> <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div> <div class=\"info\" id=\"head2\"> <p align=\"center\" class=\"para\" id=\"para1\">Here is the typical which might be provided in the page about the site <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/> </p><p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div> </div>\n",
      "\n",
      "Since there is no <a>, there is None.\n",
      "\n",
      "The contents of the first <div> tag are:\n",
      "[' ', <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div>, ' ', <div class=\"info\" id=\"head2\"> <p align=\"center\" class=\"para\" id=\"para1\">Here is the typical which might be provided in the page about the site <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/> </p><p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div>, ' ']\n",
      "\n",
      "The list iterator is <list_iterator object at 0x7f69284879d0>.\n",
      "\n",
      "The descendants of the nodes are <generator object Tag.descendants at 0x7f69283af2a0>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Navigating with the help of tags \n",
    "first_div = self_soup.div\n",
    "print( f\"1st div tag:\\n\\n{first_div}\\n\" )\n",
    "\n",
    "first_a = self_soup.a\n",
    "print(f\"Since there is no <a>, there is {first_a}.\", end=\"\\n\\n\")\n",
    "\n",
    "# Navigating with the help of .contents and .children\n",
    "con1 = first_div.contents\n",
    "print(f\"The contents of the first <div> tag are:\\n{con1}\", end=\"\\n\\n\")\n",
    "\n",
    "# Giving the list iterator of the children of the tag\n",
    "child1 = first_div.children\n",
    "print(f\"The list iterator is {child1}.\", end=\"\\n\\n\")\n",
    "\n",
    "# Giving the descendants of the div tag\n",
    "desc = first_div.descendants\n",
    "print(f\"The descendants of the nodes are {desc}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating up can be also done with the help of methods - `parent` and `parents`.\n",
    "  - `elm.parent` gives the immediate parent of the element.\n",
    "  - `elm.parents` gives a iterator to iterate over the parents of the element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"container\" id=\"main\"> <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div> <div class=\"info\" id=\"head2\"> <p align=\"center\" class=\"para\" id=\"para1\">Here is the typical which might be provided in the page about the site <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/> </p><p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div> </div> is the immediate parent of the elment div.\n",
      "\n",
      "Tihs is the list of the parents of <div class=\"container\" id=\"main\"> <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div> <div class=\"info\" id=\"head2\"> <p align=\"center\" class=\"para\" id=\"para1\">Here is the typical which might be provided in the page about the site <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/> </p><p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div> </div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Direct parent of an element\n",
    "parent_elm = self_soup.body.div\n",
    "print(f\"{parent_elm} is the immediate parent of the elment div.\", end=\"\\n\\n\")\n",
    "\n",
    "# Iterator to the parents of the element\n",
    "parent_iterator = self_soup.body.div\n",
    "print(f\"Tihs is the list of the parents of {parent_iterator}\", end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigating sideways can be done with attributes `next_sibling` and `previous_sibling` and their more functional parts `next_siblings` and `previous_siblings`.\n",
    "  - `next_sibling` gives the next elements which is in the same level as the current one. Point to note is that it can also return the string and exclamation marks which separate the tags. `previous_sibling` also works in a similar way but only it gives previous sibling.\n",
    "  \n",
    "  - `next_siblings` and `previous_siblings` simply return the generator objects of all the next and previous siblings respectively.\n",
    "\n",
    "  - Two other  are attributes are `next_element` and  `previous_element` along with other functionalities such as `next_elements` and `previous_elements`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  is the next sibling of the element.\n",
      "\n",
      "<generator object PageElement.previous_siblings at 0x7f69283119c0> are the previous siblings of the element.\n"
     ]
    }
   ],
   "source": [
    "# Giving the next sibling\n",
    "nextsibling_elm= self_soup.body.div.div.next_sibling\n",
    "print(f\"{nextsibling_elm} is the next sibling of the element.\", end=\"\\n\\n\")\n",
    "\n",
    "# Giving the previous siblings\n",
    "prevsiblings_elm = self_soup.html.body.div.div.previous_siblings\n",
    "print(f\"{prevsiblings_elm} are the previous siblings of the element.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching the tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Soup offers filters, methods and css selectors which allow us to search the tree.\n",
    "\n",
    "  - ##### Soup offers some filters which can be used to search the elements. The filters are explained as follows:\n",
    "    - _String_: Simply passing a string and soup will search for the tag name same as the given string.\n",
    "    - _Regular Expressions_: Regular Expressions can also be used to search for the elements. This allows to find the tags which start or end with a given letter.\n",
    "    - _True_: This simply gives all the elements.\n",
    "    - _List_: list might contain the strings which are to be searched across the document.\n",
    "    - _function_: Functions can also be passed which will allow us to filter tags by their arguments or content.\n",
    "\n",
    "    > `Note`: All of the above filters can be used with mojority of the methods.\n",
    "\n",
    "  - ##### The most important method to find the elements are `find` and `find_all`. There are 10 other methods which can be used. They all have their arguments similar to find and find_all.\n",
    "    \n",
    "    - `find()`: It is used to find the first element with the given properties. It has the following arguments:\n",
    "      - __name__: soup gets the first tag with the given element.\n",
    "        >soup.find(\"head\")\n",
    "\n",
    "      - __**kwargs__: soup searches for the given keyword in the tag's keywords. `class_` is used in place of `class`. \n",
    "        >soup.find(id=\"first\")\n",
    "      \n",
    "      - _attrs_: Some custom HTML attributes can not be detected by soup. Thus, they can be passed in the form of the dictionary.\n",
    "        >soup.find(attrs={'data-foo':'VALUE'})\n",
    "      \n",
    "      - _string_: This searches for strings instead of tags.\n",
    "        >soup.find( string=\"Jameieson\" )\n",
    "\n",
    "      - _recursive_: This limits the search to the specific domain of immediate child.\n",
    "        >soup.find( reursive=false)\n",
    "        \n",
    "      - `NOTE`: The above attributes also support the filters which were discussed previously.\n",
    "\n",
    "    - `find_all()`: This gives all the matching results. This has an additoinal arguement __limit__ which is used to specify the search limit to a specific value.\n",
    "      - We can even use it directly from the soup like this: `elm('')`/`soup('a')`\n",
    "\n",
    "    - Other 10 methods include _find\\_parents_, _find\\_next\\_siblings_, _find\\_previous_siblings_, _find\\_all\\_next_, _find\\_all\\_previous_ along with their variation for single matching result. Most of them support the arguments of the _find_ and _find\\_all_ methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The head tag is:\n",
      "<head><title>TITLE OF THE PAGE</title></head>\n",
      "\n",
      "The first div tag with the class 'head' is:\n",
      "<div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div>\n",
      "\n",
      "The first div tag with the class 'head' and id 'head2' are:\n",
      "<div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div>\n",
      "\n",
      "The string has been found as:\n",
      "#RANDOM_TITLE\n",
      "\n",
      "The use of regular expressions can be done to find strings such as this: Here is the typical which might be provided in the page about the site \n",
      "\n",
      "By using True as a value for class_, we can get all the tags which have a class attribute:\n",
      "<div class=\"container\" id=\"main\"> <div class=\"head\" id=\"head1\"> <h1>#RANDOM_TITLE</h1> </div> <div class=\"info\" id=\"head2\"> <p align=\"center\" class=\"para\" id=\"para1\">Here is the typical which might be provided in the page about the site <link href=\"#\" rel=\"icon\" sizes=\"414X414\"/> </p><p class=\"para\" id=\"para2\"> Here is some more info about the site. </p> </div> </div>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finding the head tag by directly inputting the head as a string in the method\n",
    "tag_head = self_soup.find(\"head\")\n",
    "print(f\"The head tag is:\\n{tag_head}\",end=\"\\n\\n\")\n",
    "\n",
    "# Finding the first div tag with the class head\n",
    "tag_div1 = self_soup.find(\"div\", class_=\"head\")\n",
    "print(f\"The first div tag with the class 'head' is:\\n{tag_div1}\", end=\"\\n\\n\")\n",
    "\n",
    "# Finding the first div tag with the class head and the id head2\n",
    "tag_div2 = self_soup.find(\"div\", class_=\"head\", id=\"head1\")\n",
    "print(f\"The first div tag with the class 'head' and id 'head2' are:\\n{tag_div2}\", end=\"\\n\\n\")\n",
    "\n",
    "# Finding the string \"provided\"\n",
    "str_find= self_soup.find(string=\"#RANDOM_TITLE\")\n",
    "print(f\"The string has been found as:\\n{str_find}\", end=\"\\n\\n\")\n",
    "\n",
    "# Using filters\n",
    "str_find1= self_soup.find(string=re.compile('[Ss]ite'))\n",
    "print(f\"The use of regular expressions can be done to find strings such as this: {str_find1}\", end=\"\\n\\n\")\n",
    "\n",
    "str_find2= self_soup.find(\"div\", class_=True)\n",
    "print(f\"By using True as a value for class_, we can get all the tags which have a class attribute:\\n{str_find2}\", end=\"\\n\\n\")\n",
    "\n",
    "# Apart from this, we can also define functions which can be used to find some element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ##### Using CSS selectors\n",
    "  - The actual selector implementation is done through _soupsieve_ package.\n",
    "  \n",
    "  - We can use the `css.select` method and can give the input of tag name, tag order, id, class, inside tags, sibling tag, tag-by-attribute-value and many more.\n",
    "  \n",
    "  - Advance features of the Soupseive offer other API such as _match_, _escape_, _filter_, _closest_. They can be found [here](https://facelessuser.github.io/soupsieve/).\n",
    "  \n",
    "  - The description of major methods is given here:\n",
    "\n",
    "    - By tag name, tag ordering, inside tag, sibling tags:\n",
    "      - `soup.css.select('a')`\n",
    "      - `soup.css.select('html body div a')`\n",
    "      - `soup.css.select('head > title ')`\n",
    "      - `soup.css.select('#head1 ~ .para')`[This gives all the tags with the matching class name para, use + insted of ~ for one.]\n",
    "    \n",
    "    - By id, class\n",
    "      - `soup.css.select('#head1')`\n",
    "      - `soup.css.select('.para')`\n",
    "    \n",
    "    - By attribute value of the tag and checking whether the tag with a certain attribute is present or not.\n",
    "      - `soup.css.select( link[href=\"#\"] )`\n",
    "      - `soup.css.select( link[href] )`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
